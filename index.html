<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Benchmark repository for optimization &#8212; benchopt 1.1.1.dev37 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Command Line Interface (CLI) Documentation" href="cli.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">
          benchopt</a>
        <span class="navbar-text navbar-version pull-left"><b>1.1.1.dev37</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="cli.html">CLI</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="how.html">Write a benchmark</a></li>
                <li><a href="https://benchopt.github.io/results">Results</a></li>
                <li><a href="whats_new.html">What's new</a></li>
                <li><a href="https://github.com/benchopt/benchOpt">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command Line Interface (CLI) Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Python API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="how.html">Write a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="publish.html">Publish benchmark results</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">BenchOpt configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/benchopt/benchopt">Fork BenchOpt on Github</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Benchmark repository for optimization</a><ul>
<li><a class="reference internal" href="#install">Install</a></li>
<li><a class="reference internal" href="#example-of-command-line-usage-on-the-lasso-benchmark">Example of command line usage on the Lasso benchmark</a></li>
<li><a class="reference internal" href="#some-available-benchmarks">Some available benchmarks</a></li>
<li><a class="reference internal" href="#benchmark-results">Benchmark results</a></li>
</ul>
</li>
<li><a class="reference internal" href="#contents">Contents</a></li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <section id="benchmark-repository-for-optimization">
<h1>Benchmark repository for optimization<a class="headerlink" href="#benchmark-repository-for-optimization" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/benchopt/benchOpt/actions/workflows/test.yml"><img alt="Test Status" src="https://github.com/benchopt/benchOpt/actions/workflows/test.yml/badge.svg" /></a> <a class="reference external" href="https://www.python.org/downloads/release/python-360/"><img alt="Python 3.6+" src="https://img.shields.io/badge/python-3.6%2B-blue" /></a> <a class="reference external" href="https://codecov.io/gh/benchopt/benchOpt"><img alt="codecov" src="https://codecov.io/gh/benchopt/benchOpt/branch/master/graph/badge.svg" /></a></p>
<p>BenchOpt is a package to simplify, make more transparent and
more reproducible the comparisons of optimization algorithms.</p>
<p>BenchOpt is written in Python but it is available with
<a class="reference external" href="auto_examples/plot_run_benchmark_python_R_julia.html">many programming languages</a>.
So far it has been tested with <a class="reference external" href="https://www.python.org/">Python</a>,
<a class="reference external" href="https://www.r-project.org/">R</a>, <a class="reference external" href="https://julialang.org/">Julia</a>
and compiled binaries written in C/C++ available via a terminal
command. If it can be installed via
<a class="reference external" href="https://docs.conda.io/en/latest/">conda</a> it should just work!</p>
<p>BenchOpt is used through a command line as documented
in <a class="reference internal" href="cli.html#cli-documentation"><span class="std std-ref">Command Line Interface (CLI) Documentation</span></a>. Ultimately running and replicating an
optimization benchmark should be <strong>as simple as doing</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/benchopt/benchmark_logreg_l2
$ benchopt install --env ./benchmark_logreg_l2
$ benchopt run --env ./benchmark_logreg_l2
</pre></div>
</div>
<p>Running these commands will fetch the benchmark files, install the benchmark
requirements in a dedicated environment <cite>benchop_benchmark_logreg_l2</cite> and
give you a benchmark plot on l2-regularized logistic regression:</p>
<figure class="align-center">
<a class="reference external image-reference" href="how.html"><img alt="_images/sphx_glr_plot_run_benchmark_001.png" src="_images/sphx_glr_plot_run_benchmark_001.png" style="width: 512.0px; height: 384.0px;" /></a>
</figure>
<p>Learn how to <a class="reference internal" href="how.html#how"><span class="std std-ref">Write a benchmark</span></a>.</p>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h2>
<p>This package can be installed through <cite>pip</cite>. To get the <strong>last release</strong>, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install benchopt
</pre></div>
</div>
<p>And to get the <strong>latest development version</strong>, you can use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install -U https://github.com/benchopt/benchOpt/archive/master.zip
</pre></div>
</div>
<p>This will install the command line tool to run the benchmark. Then, existing
benchmarks can be retrieved from git or created locally. To discover which
benchmarks are presently available look for
<a class="reference external" href="https://github.com/benchopt/">benchmark_* repositories on GitHub</a>,
such as for <a class="reference external" href="https://github.com/benchopt/benchmark_lasso">Lasso – l1-regularized linear regression</a>.
This benchmark can then be retrieved locally with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone https://github.com/benchopt/benchmark_lasso.git
</pre></div>
</div>
</section>
<section id="example-of-command-line-usage-on-the-lasso-benchmark">
<h2>Example of command line usage on the Lasso benchmark<a class="headerlink" href="#example-of-command-line-usage-on-the-lasso-benchmark" title="Permalink to this headline">¶</a></h2>
<p>This section illustrates benchopt’s command line interface on the <a class="reference external" href="https://github.com/benchopt/benchmark_lasso">Lasso benchmark</a>; the syntax is applicable to any benchmark.</p>
<p>To install all requirements and dependencies of the benchmark, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ benchopt install --env ./benchmark_lasso
</pre></div>
</div>
<p>To run benchmarks on all datasets and with all solvers, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ benchopt run --env ./benchmark_lasso
</pre></div>
</div>
<p>To run only the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> and <code class="docutils literal notranslate"><span class="pre">celer</span></code> solvers, on the <code class="docutils literal notranslate"><span class="pre">simulated</span></code> and <code class="docutils literal notranslate"><span class="pre">finance</span></code> datasets, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ benchopt run --env ./benchmark_lasso -s sklearn -s celer -d simulated -d finance
</pre></div>
</div>
<p>Some solvers and dataset have parameters; by default all combinations are run.
If you want to run a specific configuration, pass it explicitly, e.g., to run the python-pgd solver only with its parameter <code class="docutils literal notranslate"><span class="pre">use_acceleration</span></code> set to True, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ benchopt run --env ./benchmark_lasso -s python-pgd[use_acceleration=True]
</pre></div>
</div>
<p>Use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ benchopt run -h
</pre></div>
</div>
<p>to get more details about the different options read the
<a class="reference internal" href="cli.html#cli-documentation"><span class="std std-ref">Command Line Interface (CLI) Documentation</span></a>.</p>
</section>
<section id="some-available-benchmarks">
<h2>Some available benchmarks<a class="headerlink" href="#some-available-benchmarks" title="Permalink to this headline">¶</a></h2>
<p><strong>Notation:</strong>  In what follows, n (or n_samples) stands for the number of samples and p (or n_features) stands for the number of features.</p>
<div class="math notranslate nohighlight">
\[y \in \mathbb{R}^n, X = [x_1^\top, \dots, x_n^\top]^\top \in \mathbb{R}^{n \times p}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_ols">Ordinary Least Squares (OLS)</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_ols/actions"><img alt="Build Status OLS" src="https://github.com/benchopt/benchmark_ols/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \frac{1}{2} \|y - Xw\|^2_2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_nnls">Non-Negative Least Squares (NNLS)</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_nnls/actions"><img alt="Build Status NNLS" src="https://github.com/benchopt/benchmark_nnls/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w \geq 0} \frac{1}{2} \|y - Xw\|^2_2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_lasso">LASSO: L1-regularized least squares</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_lasso/actions"><img alt="Build Status Lasso" src="https://github.com/benchopt/benchmark_lasso/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \frac{1}{2} \|y - Xw\|^2_2 + \lambda \|w\|_1\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l2">L2-regularized logistic regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l2/actions"><img alt="Build Status LogRegL2" src="https://github.com/benchopt/benchmark_logreg_l2/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \sum_{i=1}^{n} \log(1 + \exp(-y_i x_i^\top w)) + \frac{\lambda}{2} \|w\|_2^2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l1">L1-regularized logistic regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l1/actions"><img alt="Build Status LogRegL1" src="https://github.com/benchopt/benchmark_logreg_l1/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \sum_{i=1}^{n} \log(1 + \exp(-y_i x_i^\top w)) + \lambda \|w\|_1\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_huber_l2">L2-regularized Huber regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_huber_l2/actions"><img alt="Build Status HuberL2" src="https://github.com/benchopt/benchmark_huber_l2/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w, \sigma} {\sum_{i=1}^n \left(\sigma + H_{\epsilon}\left(\frac{X_{i}w - y_{i}}{\sigma}\right)\sigma\right) + \lambda {||w||_2}^2}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}H_{\epsilon}(z) = \begin{cases}
       z^2, &amp; \text {if } |z| &lt; \epsilon, \\
       2\epsilon|z| - \epsilon^2, &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_quantile_regression">L1-regularized quantile regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_quantile_regression/actions"><img alt="Build Status QuantileRegL1" src="https://github.com/benchopt/benchmark_quantile_regression/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w} \frac{1}{n} \sum_{i=1}^{n} PB_q(y_i - X_i w) + \lambda ||w||_1.\]</div>
<p>where <span class="math notranslate nohighlight">\(PB_q\)</span> is the pinball loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split}PB_q(t) = q \max(t, 0) + (1 - q) \max(-t, 0) =
\begin{cases}
    q t, &amp; t &gt; 0, \\
    0,    &amp; t = 0, \\
    (1-q) t, &amp; t &lt; 0
\end{cases}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_linear_ica">Linear ICA</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_linear_ica/actions"><img alt="Build Status LinearICA" src="https://github.com/benchopt/benchmark_linear_ica/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<p>Given some data <span class="math notranslate nohighlight">\(X  \in \mathbb{R}^{d \times n}\)</span> assumed to be linearly
related to unknown independent sources <span class="math notranslate nohighlight">\(S  \in \mathbb{R}^{d \times n}\)</span> with</p>
<div class="math notranslate nohighlight">
\[X = A S\]</div>
<p>where <span class="math notranslate nohighlight">\(A  \in \mathbb{R}^{d \times d}\)</span> is also unknown, the objective of
linear ICA is to recover <span class="math notranslate nohighlight">\(A\)</span> up to permutation and scaling of its columns.
The objective in this benchmark is related to some estimation on <span class="math notranslate nohighlight">\(A\)</span>
quantified with the so-called AMARI distance.</p>
<p>See <a class="reference external" href="https://github.com/benchopt/">benchmark_* repositories on GitHub</a> for more.</p>
</section>
<section id="benchmark-results">
<h2>Benchmark results<a class="headerlink" href="#benchmark-results" title="Permalink to this headline">¶</a></h2>
<p>All the public benchmark results are available at <a class="reference external" href="https://benchopt.github.io/results/">BenchOpt Benchmarks results</a>.</p>
<p><strong>Publish results</strong>: You can directly publish the result of a run of <code class="docutils literal notranslate"><span class="pre">benchopt</span></code> on <a class="reference external" href="https://benchopt.github.io/results/">BenchOpt Benchmarks results</a>. You can have a look at this page to <a class="reference internal" href="publish.html#publish-doc"><span class="std std-ref">Publish benchmark results</span></a>.</p>
</section>
</section>
<section id="contents">
<h1>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command Line Interface (CLI) Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Python API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="how.html">Write a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="publish.html">Publish benchmark results</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">BenchOpt configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/benchopt/benchopt">Fork BenchOpt on Github</a></li>
</ul>
</div>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020-2020, Benchopt contributors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>