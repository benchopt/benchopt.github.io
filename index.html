<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Benchopt: Benchmark repository for optimization &#8212; benchopt 1.3.2.dev14 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Command line interface (CLI)" href="cli.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">
          benchopt</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3.2.dev14</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="cli.html">CLI</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="https://benchopt.github.io/results">Results</a></li>
                <li><a href="whats_new.html">What's new</a></li>
                <li><a href="https://github.com/benchopt/benchopt">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command line interface (CLI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="how.html">Write a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="publish.html">Publish benchmark results</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">BenchOpt configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced.html">Advanced functionalities in a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/benchopt/benchopt">Fork benchopt on Github</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Benchopt: Benchmark repository for optimization</a><ul>
<li><a class="reference internal" href="#install">Install</a></li>
<li><a class="reference internal" href="#run-a-benchmark">Run a benchmark</a></li>
<li><a class="reference internal" href="#benchmark-results">Benchmark results</a></li>
</ul>
</li>
<li><a class="reference internal" href="#frequently-asked-questions-faq">Frequently asked questions (FAQ)</a><ul>
<li><a class="reference internal" href="#write-a-benchmark">Write a benchmark</a></li>
<li><a class="reference internal" href="#curve-sampling">Curve sampling</a></li>
<li><a class="reference internal" href="#re-using-code-in-a-benchmark">Re-using code in a benchmark</a></li>
<li><a class="reference internal" href="#parallel-run">Parallel run</a></li>
<li><a class="reference internal" href="#citing-benchopt">Citing Benchopt</a></li>
<li><a class="reference internal" href="#other-functionalities">Other functionalities</a></li>
</ul>
</li>
<li><a class="reference internal" href="#how-to-contribute">How to contribute</a><ul>
<li><a class="reference internal" href="#bug-report-and-feature-request">Bug report and feature request</a></li>
<li><a class="reference internal" href="#code-contribution">Code contribution</a></li>
<li><a class="reference internal" href="#documentation">Documentation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#some-available-benchmarks">Some available benchmarks</a></li>
<li><a class="reference internal" href="#website-contents">Website contents</a></li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <section id="benchopt-benchmark-repository-for-optimization">
<h1>Benchopt: Benchmark repository for optimization<a class="headerlink" href="#benchopt-benchmark-repository-for-optimization" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/benchopt/benchopt/actions/workflows/test.yml"><img alt="Test Status" src="https://github.com/benchopt/benchopt/actions/workflows/test.yml/badge.svg" /></a> <a class="reference external" href="https://www.python.org/downloads/release/python-360/"><img alt="Python 3.6+" src="https://img.shields.io/badge/python-3.6%2B-blue" /></a> <a class="reference external" href="https://codecov.io/gh/benchopt/benchopt"><img alt="codecov" src="https://codecov.io/gh/benchopt/benchopt/branch/master/graph/badge.svg" /></a></p>
<p>Benchopt is a package to make the comparison of optimizations algorithms simple, transparent and reproducible.</p>
<p>It is written in Python but is available with
<a class="reference external" href="auto_examples/plot_run_benchmark_python_R.html">many programming languages</a>.
So far it has been tested with <a class="reference external" href="https://www.python.org/">Python</a>,
<a class="reference external" href="https://www.r-project.org/">R</a>, <a class="reference external" href="https://julialang.org/">Julia</a>
and compiled binaries written in C/C++ available via a terminal
command.
If a solver can be installed via
<a class="reference external" href="https://docs.conda.io/en/latest/">conda</a>, it should just work in benchopt!</p>
<p>Benchopt is used through a command line as documented
in the <a class="reference internal" href="cli.html#cli-documentation"><span class="std std-ref">Command line interface (CLI)</span></a>.
Once benchopt is installed, running and replicating an optimization benchmark is <strong>as simple as doing</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt1:before {
  content: "$ ";
}
</style><span class="prompt1">git<span class="w"> </span>clone<span class="w"> </span>https://github.com/benchopt/benchmark_logreg_l2</span>
<span class="prompt1">benchopt<span class="w"> </span>install<span class="w"> </span>--env<span class="w"> </span>./benchmark_logreg_l2</span>
<span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>--env<span class="w"> </span>./benchmark_logreg_l2</span>
</pre></div></div><p>Running these commands will fetch the benchmark files, install the benchmark
requirements in a dedicated environment called <code class="docutils literal notranslate"><span class="pre">benchopt_benchmark_logreg_l2</span></code> and
give you a benchmark plot on l2-regularized logistic regression:</p>
<figure class="align-center">
<a class="reference external image-reference" href="how.html"><img alt="_images/sphx_glr_plot_run_benchmark_003.png" src="_images/sphx_glr_plot_run_benchmark_003.png" style="width: 512.0px; height: 384.0px;" /></a>
</figure>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h2>
<p>This package can be installed through <cite>pip</cite>.  In order to allow benchopt to automatically
install solvers dependencies, the install needs to be done in a <cite>conda</cite> environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>benchopt<span class="w"> </span>python</span>
<span class="prompt1">conda<span class="w"> </span>activate<span class="w"> </span>benchopt</span>
</pre></div></div><p>To get the <strong>latest release</strong>, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">pip<span class="w"> </span>install<span class="w"> </span>benchopt</span>
</pre></div></div><p>And to get the <strong>latest development version</strong>, you can use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>-i<span class="w"> </span>https://test.pypi.org/simple/<span class="w"> </span>benchopt</span>
</pre></div></div><p>This will install the command line tool to run the benchmark. Then, existing
benchmarks can be retrieved from GitHub or created locally. To discover which
benchmarks are presently available look for
<a class="reference external" href="https://github.com/benchopt/">benchmark_* repositories on GitHub</a>,
such as for <a class="reference external" href="https://github.com/benchopt/benchmark_lasso">Lasso – l1-regularized linear regression</a>.
This benchmark can be retrieved locally with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>clone<span class="w"> </span>https://github.com/benchopt/benchmark_lasso.git</span>
</pre></div></div></section>
<section id="run-a-benchmark">
<h2>Run a benchmark<a class="headerlink" href="#run-a-benchmark" title="Permalink to this headline">¶</a></h2>
<p>This section illustrates benchopt’s command line interface on the <a class="reference external" href="https://github.com/benchopt/benchmark_lasso">Lasso benchmark</a>; the syntax is applicable to any benchmark.
All this section assumes that you are in the parent folder of the <code class="docutils literal notranslate"><span class="pre">benchmark_lasso</span></code> folder.
The <code class="docutils literal notranslate"><span class="pre">--env</span></code> flag specifies that everything is run in the <code class="docutils literal notranslate"><span class="pre">benchopt_benchmark_lasso</span></code> <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment.</p>
<p><strong>Installing benchmark dependencies</strong>: <code class="docutils literal notranslate"><span class="pre">benchopt</span></code> exposes a CLI to install solvers’ dependencies automatically.
It only works inside a <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment. To install all requirements of the benchmark, make sure a <code class="docutils literal notranslate"><span class="pre">conda</span></code>
environment is activated and run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>install<span class="w"> </span>--env<span class="w"> </span>./benchmark_lasso</span>
</pre></div></div><p><strong>Run a benchmark</strong>: to run benchmarks on all datasets and with all solvers, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>--env<span class="w"> </span>./benchmark_lasso</span>
</pre></div></div><p>The command <code class="docutils literal notranslate"><span class="pre">benchopt</span> <span class="pre">run</span></code> can also be used outside of a <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment without the flag <code class="docutils literal notranslate"><span class="pre">-e/--env</span></code>.
In that case, the benchmark will only run solvers that are currently installed.</p>
<p><strong>Run only some solvers and datasets</strong>: to run only the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> and <code class="docutils literal notranslate"><span class="pre">celer</span></code> solvers, on the <code class="docutils literal notranslate"><span class="pre">simulated</span></code> and <code class="docutils literal notranslate"><span class="pre">finance</span></code> datasets, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>--env<span class="w"> </span>./benchmark_lasso<span class="w"> </span>-s<span class="w"> </span>sklearn<span class="w"> </span>-s<span class="w"> </span>celer<span class="w"> </span>-d<span class="w"> </span>simulated<span class="w"> </span>-d<span class="w"> </span>finance</span>
</pre></div></div><p><strong>Run a solver or dataset with specific parameters</strong>:  some solvers and datasets have parameters; by default all combinations are run.
If you want to run a specific configuration, pass it explicitly, e.g., to run the <code class="docutils literal notranslate"><span class="pre">python-pgd</span></code> solver only with its parameter <code class="docutils literal notranslate"><span class="pre">use_acceleration</span></code> set to True, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>--env<span class="w"> </span>./benchmark_lasso<span class="w"> </span>-s<span class="w"> </span>python-pgd<span class="o">[</span><span class="nv">use_acceleration</span><span class="o">=</span>True<span class="o">]</span></span>
</pre></div></div><p><strong>Set the number of repetitions</strong>: the benchmark are repeated 5 times by default for greater precision. To run the benchmark 10 times, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>--env<span class="w"> </span>./benchmark_lasso<span class="w"> </span>-r<span class="w"> </span><span class="m">10</span></span>
</pre></div></div><p><strong>Passing option through configuration file</strong>: all options of <code class="docutils literal notranslate"><span class="pre">benchopt</span> <span class="pre">run</span></code> can be passed through a YAML configuration file, together with <code class="docutils literal notranslate"><span class="pre">--config</span> <span class="pre">&lt;configuration_file_name.yml&gt;</span></code>.
The options are defined using the same name as the CLI options.
An example of configuration file is:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">objective-filter</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Lasso Regression[fit_intercept=False,reg=0.5]</span>
<span class="nt">dataset</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">simulated</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">leukemia</span>
<span class="nt">solver</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">celer</span>
<span class="nt">force-solver</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cd</span>
<span class="nt">n-repetitions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>When options are passed both via file and CLI, the CLI takes precedence.</p>
<p><strong>Getting help</strong>: use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">benchopt<span class="w"> </span>run<span class="w"> </span>-h</span>
</pre></div></div><p>to get more details about the different options.
You can also read the <a class="reference internal" href="cli.html#cli-documentation"><span class="std std-ref">Command line interface (CLI)</span></a>.</p>
</section>
<section id="benchmark-results">
<h2>Benchmark results<a class="headerlink" href="#benchmark-results" title="Permalink to this headline">¶</a></h2>
<p>All the public benchmark results are available at <a class="reference external" href="https://benchopt.github.io/results/">Benchopt Benchmarks results</a>.</p>
<p><strong>Publish results</strong>: You can directly publish the result of a run of <code class="docutils literal notranslate"><span class="pre">benchopt</span></code> on <a class="reference external" href="https://benchopt.github.io/results/">Benchopt Benchmarks results</a>. You can have a look at this page to <a class="reference internal" href="publish.html#publish-doc"><span class="std std-ref">Publish benchmark results</span></a>.</p>
</section>
</section>
<section id="frequently-asked-questions-faq">
<h1>Frequently asked questions (FAQ)<a class="headerlink" href="#frequently-asked-questions-faq" title="Permalink to this headline">¶</a></h1>
<section id="write-a-benchmark">
<h2>Write a benchmark<a class="headerlink" href="#write-a-benchmark" title="Permalink to this headline">¶</a></h2>
<p>Learn how to <a class="reference internal" href="how.html#how"><span class="std std-ref">Write a benchmark</span></a>, including creating an objective, a solver, and
a dataset.</p>
</section>
<section id="curve-sampling">
<h2>Curve sampling<a class="headerlink" href="#curve-sampling" title="Permalink to this headline">¶</a></h2>
<p>Benchopt allows to sample both black-boxed solvers and solvers that allow for callbacks. Learn <a class="reference internal" href="convergence_curves.html#convergence-curves"><span class="std std-ref">How are the convergence curves sampled?</span></a>. Note that the sampling strategy can also be tweaked on a per-solver basis, as described in: <a class="reference internal" href="advanced.html#sampling-strategy"><span class="std std-ref">Changing the strategy to grow the stop_val</span></a>.</p>
</section>
<section id="re-using-code-in-a-benchmark">
<h2>Re-using code in a benchmark<a class="headerlink" href="#re-using-code-in-a-benchmark" title="Permalink to this headline">¶</a></h2>
<p>For some solver and datasets, it is necessary to share some operations or pre-processing steps. Benchopt allows to factorize this code by <a class="reference internal" href="advanced.html#benchmark-utils-import"><span class="std std-ref">Reusing some code in a benchmark</span></a>.</p>
</section>
<section id="parallel-run">
<h2>Parallel run<a class="headerlink" href="#parallel-run" title="Permalink to this headline">¶</a></h2>
<p>Benchopt allows to run different benchmarked methods in parallel, either with <code class="docutils literal notranslate"><span class="pre">joblib</span></code> using <code class="docutils literal notranslate"><span class="pre">-j</span> <span class="pre">4</span></code> to run on multiple CPUs of a single machine or using SLURM, as described in <a class="reference internal" href="advanced.html#slurm-run"><span class="std std-ref">Running the benchmark on a SLURM cluster</span></a>.</p>
</section>
<section id="citing-benchopt">
<h2>Citing Benchopt<a class="headerlink" href="#citing-benchopt" title="Permalink to this headline">¶</a></h2>
<p>If you use <code class="docutils literal notranslate"><span class="pre">Benchopt</span></code> in a scientific publication, please cite the following paper</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">benchopt</span><span class="p">,</span>
<span class="w">   </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Moreau, Thomas and Massias, Mathurin and Gramfort, Alexandre and Ablin, Pierre</span>
<span class="s">             and Bannier, Pierre-Antoine and Charlier, Benjamin and Dagréou, Mathieu and Dupré la Tour, Tom</span>
<span class="s">             and Durif, Ghislain and F. Dantas, Cassio and Klopfenstein, Quentin</span>
<span class="s">             and Larsson, Johan and Lai, En and Lefort, Tanguy and Malézieux, Benoit</span>
<span class="s">             and Moufad, Badr and T. Nguyen, Binh and Rakotomamonjy, Alain and Ramzi, Zaccharie</span>
<span class="s">             and Salmon, Joseph and Vaiter, Samuel}</span><span class="p">,</span>
<span class="w">   </span><span class="na">title</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{Benchopt: Reproducible, efficient and collaborative optimization benchmarks}</span><span class="p">,</span>
<span class="w">   </span><span class="na">year</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="s">{2022}</span><span class="p">,</span>
<span class="w">   </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{NeurIPS}</span><span class="p">,</span>
<span class="w">   </span><span class="na">url</span><span class="w">    </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/2206.13424}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="other-functionalities">
<h2>Other functionalities<a class="headerlink" href="#other-functionalities" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Some solvers are not compatible with certain datasets or objective configurations. This can be accommodated by <a class="reference internal" href="advanced.html#skiping-solver"><span class="std std-ref">Skipping a solver for a given problem</span></a>.</p></li>
<li><p>For some solvers, it is necessary to cache some pre-compilation for fair benchmarks. This can easily be done with benchopt, as described in <a class="reference internal" href="advanced.html#precompilation"><span class="std std-ref">Caching pre-compilation and warmup effects</span></a>.</p></li>
</ul>
</section>
</section>
<section id="how-to-contribute">
<span id="contrib-doc"></span><h1>How to contribute<a class="headerlink" href="#how-to-contribute" title="Permalink to this headline">¶</a></h1>
<section id="bug-report-and-feature-request">
<h2>Bug report and feature request<a class="headerlink" href="#bug-report-and-feature-request" title="Permalink to this headline">¶</a></h2>
<p>We use benchopt <a class="reference external" href="https://github.com/benchopt/benchopt/issues">GitHub repo</a> to track all bugs and feature requests; feel free to open
an issue if you have found a bug or wish to see a feature implemented.</p>
</section>
<section id="code-contribution">
<h2>Code contribution<a class="headerlink" href="#code-contribution" title="Permalink to this headline">¶</a></h2>
<p>The preferred way to contribute to benchopt is to fork the <a class="reference external" href="https://github.com/benchopt/benchopt/">main
repository</a> on GitHub,
then submit a “Pull Request” (PR).</p>
<p>In the first few steps, we explain how to locally install benchopt, and
how to set up your git repository:</p>
<ol class="arabic">
<li><p><a class="reference external" href="https://github.com/join">Create an account</a> on
GitHub if you do not already have one.</p></li>
<li><p>Fork the <a class="reference external" href="https://github.com/benchopt/benchopt">project repository</a>: click on the ‘Fork’
button near the top of the page. This creates a copy of the code under your
account on the GitHub user account. For more details on how to fork a
repository see <a class="reference external" href="https://help.github.com/articles/fork-a-repo/">this guide</a>.</p></li>
<li><p>Clone your fork of the benchopt repo from your GitHub account to your
local disk:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>clone<span class="w"> </span>git@github.com:YourLogin/benchopt.git</span>
<span class="prompt1"><span class="nb">cd</span><span class="w"> </span>benchopt</span>
</pre></div></div></li>
</ol>
<ol class="arabic" id="upstream" start="4">
<li><p>Add the <code class="docutils literal notranslate"><span class="pre">upstream</span></code> remote. This saves a reference to the main
benchopt repository, which you can use to keep your repository
synchronized with the latest changes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>remote<span class="w"> </span>add<span class="w"> </span>upstream<span class="w"> </span>https://github.com/benchopt/benchopt</span>
</pre></div></div></li>
<li><p>Check that the <cite>upstream</cite> and <cite>origin</cite> remote aliases are configured correctly
by running <cite>git remote -v</cite> which should display:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">origin</span>  <span class="n">git</span><span class="nd">@github</span><span class="o">.</span><span class="n">com</span><span class="p">:</span><span class="n">YourLogin</span><span class="o">/</span><span class="n">benchopt</span><span class="o">.</span><span class="n">git</span> <span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
<span class="n">origin</span>  <span class="n">git</span><span class="nd">@github</span><span class="o">.</span><span class="n">com</span><span class="p">:</span><span class="n">YourLogin</span><span class="o">/</span><span class="n">benchopt</span><span class="o">.</span><span class="n">git</span> <span class="p">(</span><span class="n">push</span><span class="p">)</span>
<span class="n">upstream</span>        <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">benchopt</span><span class="o">/</span><span class="n">benchopt</span> <span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
<span class="n">upstream</span>        <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">benchopt</span><span class="o">/</span><span class="n">benchopt</span> <span class="p">(</span><span class="n">push</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>You should now have a working installation of benchopt, and your git
repository properly configured. The next steps now describe the process of
modifying code and submitting a PR:</p>
<ol class="arabic" start="6">
<li><p>Synchronize your <code class="docutils literal notranslate"><span class="pre">main</span></code> branch with the <code class="docutils literal notranslate"><span class="pre">upstream/main</span></code> branch,
more details on <a class="reference external" href="https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/syncing-a-fork">GitHub Docs</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>switch<span class="w"> </span>main</span>
<span class="prompt1">git<span class="w"> </span>fetch<span class="w"> </span>upstream</span>
<span class="prompt1">git<span class="w"> </span>merge<span class="w"> </span>upstream/main</span>
</pre></div></div></li>
<li><p>Create a feature branch to hold your development changes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>switch<span class="w"> </span>-c<span class="w"> </span>my_feature</span>
</pre></div></div><p>and start making changes. Always use a feature branch. It’s good
practice to never work on the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch!</p>
</li>
<li><p>Develop the feature on your feature branch on your computer, using Git to
do the version control. When you’re done editing, add changed files using
<code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">add</span></code> and then <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">commit</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>add<span class="w"> </span>modified_files</span>
<span class="prompt1">git<span class="w"> </span>commit</span>
</pre></div></div><p>to record your changes in Git, then push the changes to your GitHub
account with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>push<span class="w"> </span>-u<span class="w"> </span>origin<span class="w"> </span>my_feature</span>
</pre></div></div></li>
<li><p>Follow <a class="reference external" href="https://help.github.com/articles/creating-a-pull-request-from-a-fork">these</a> instructions
to create a pull request from your fork.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is often helpful to keep your local feature branch synchronized with the latest
changes of the main benchopt repository:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">git<span class="w"> </span>fetch<span class="w"> </span>upstream</span>
<span class="prompt1">git<span class="w"> </span>merge<span class="w"> </span>upstream/main</span>
</pre></div></div></div>
</section>
<section id="documentation">
<h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<p>We are glad to accept any sort of documentation: function docstrings,
reStructuredText documents (like this one), tutorials, etc. reStructuredText
documents live in the source code repository under the <code class="docutils literal notranslate"><span class="pre">doc/</span></code> directory.</p>
<p>You can edit the documentation using any text editor, and then generate the
HTML output by typing, in a shell:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">pip<span class="w"> </span>install<span class="w"> </span>benchopt<span class="o">[</span>doc<span class="o">]</span></span>
<span class="prompt1"><span class="nb">cd</span><span class="w"> </span>doc/</span>
<span class="prompt1">make<span class="w"> </span>html</span>
<span class="prompt1">firefox<span class="w"> </span>_build/html/index.html</span>
</pre></div></div></section>
</section>
<section id="some-available-benchmarks">
<h1>Some available benchmarks<a class="headerlink" href="#some-available-benchmarks" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some benchmarks are briefly described in the list below. For a complete
list of benchmarks, see GitHub repositories of the form <a class="reference external" href="https://github.com/orgs/benchopt/repositories?q=benchmark_&amp;type=all&amp;language=&amp;sort=stargazers/">benchopt/benchmark_*</a>.</p>
</div>
<p><strong>Notation:</strong>  In what follows, <span class="math notranslate nohighlight">\(n\)</span> (or <code class="docutils literal notranslate"><span class="pre">n_samples</span></code>) stands for the number of samples and <span class="math notranslate nohighlight">\(p\)</span> (or <code class="docutils literal notranslate"><span class="pre">n_features</span></code>) stands for the number of features.</p>
<div class="math notranslate nohighlight">
\[y \in \mathbb{R}^n, X = [x_1^\top, \dots, x_n^\top]^\top \in \mathbb{R}^{n \times p}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_ols">Ordinary Least Squares (OLS)</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_ols/actions"><img alt="Build Status OLS" src="https://github.com/benchopt/benchmark_ols/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \frac{1}{2} \|y - Xw\|^2_2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_nnls">Non-Negative Least Squares (NNLS)</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_nnls/actions"><img alt="Build Status NNLS" src="https://github.com/benchopt/benchmark_nnls/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w \geq 0} \frac{1}{2} \|y - Xw\|^2_2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_lasso">LASSO: L1-regularized least squares</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_lasso/actions"><img alt="Build Status Lasso" src="https://github.com/benchopt/benchmark_lasso/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \frac{1}{2} \|y - Xw\|^2_2 + \lambda \|w\|_1\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l2">L2-regularized logistic regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l2/actions"><img alt="Build Status LogRegL2" src="https://github.com/benchopt/benchmark_logreg_l2/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \sum_{i=1}^{n} \log(1 + \exp(-y_i x_i^\top w)) + \frac{\lambda}{2} \|w\|_2^2\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l1">L1-regularized logistic regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_logreg_l1/actions"><img alt="Build Status LogRegL1" src="https://github.com/benchopt/benchmark_logreg_l1/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_w \sum_{i=1}^{n} \log(1 + \exp(-y_i x_i^\top w)) + \lambda \|w\|_1\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_huber_l2">L2-regularized Huber regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_huber_l2/actions"><img alt="Build Status HuberL2" src="https://github.com/benchopt/benchmark_huber_l2/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w, \sigma} {\sum_{i=1}^n \left(\sigma + H_{\epsilon}\left(\frac{X_{i}w - y_{i}}{\sigma}\right)\sigma\right) + \lambda {\|w\|_2}^2}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}H_{\epsilon}(z) = \begin{cases}
       z^2, &amp; \text {if } |z| &lt; \epsilon, \\
       2\epsilon|z| - \epsilon^2, &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_quantile_regression">L1-regularized quantile regression</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_quantile_regression/actions"><img alt="Build Status QuantileRegL1" src="https://github.com/benchopt/benchmark_quantile_regression/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\min_{w} \frac{1}{n} \sum_{i=1}^{n} PB_q(y_i - X_i w) + \lambda ||w||_1.\]</div>
<p>where <span class="math notranslate nohighlight">\(PB_q\)</span> is the pinball loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split}PB_q(t) = q \max(t, 0) + (1 - q) \max(-t, 0) =
\begin{cases}
    q t, &amp; t &gt; 0, \\
    0,    &amp; t = 0, \\
    (q - 1) t, &amp; t &lt; 0
\end{cases}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_linear_ica">Linear ICA</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_linear_ica/actions"><img alt="Build Status LinearICA" src="https://github.com/benchopt/benchmark_linear_ica/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<p>Given some data <span class="math notranslate nohighlight">\(X  \in \mathbb{R}^{d \times n}\)</span> assumed to be linearly
related to unknown independent sources <span class="math notranslate nohighlight">\(S  \in \mathbb{R}^{d \times n}\)</span> with</p>
<div class="math notranslate nohighlight">
\[X = A S\]</div>
<p>where <span class="math notranslate nohighlight">\(A  \in \mathbb{R}^{d \times d}\)</span> is also unknown, the objective of
linear ICA is to recover <span class="math notranslate nohighlight">\(A\)</span> up to permutation and scaling of its columns.
The objective in this benchmark is related to some estimation on <span class="math notranslate nohighlight">\(A\)</span>
quantified with the so-called AMARI distance.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/benchopt/benchmark_jointdiag">Approximate Joint Diagonalization (AJD)</a>: <a class="reference external" href="https://github.com/benchopt/benchmark_jointdiag/actions"><img alt="Build Status JointDiag" src="https://github.com/benchopt/benchmark_jointdiag/workflows/Tests/badge.svg" /></a></p></li>
</ul>
<p>Given n square symmetric positive matrices <span class="math notranslate nohighlight">\(C^i\)</span>, it consists of solving
the following problem:</p>
<div class="math notranslate nohighlight">
\[\min_B \frac{1}{2n} \sum_{i=1}^n \log |\textrm{diag} (B C^i B^{\top}) | - \log | B C^i B^{\top} |\]</div>
<p>where <span class="math notranslate nohighlight">\(|\cdot|\)</span> stands for the matrix determinant and <span class="math notranslate nohighlight">\(\textrm{diag}\)</span> stands
for the operator that keeps only the diagonal elements of a matrix. Optionally, the
matrix <span class="math notranslate nohighlight">\(B\)</span> can be enforced to be orthogonal.</p>
<p>See <a class="reference external" href="https://github.com/benchopt/">benchmark_* repositories on GitHub</a> for more.</p>
</section>
<section id="website-contents">
<h1>Website contents<a class="headerlink" href="#website-contents" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command line interface (CLI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="how.html">Write a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="publish.html">Publish benchmark results</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">BenchOpt configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced.html">Advanced functionalities in a benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/benchopt/benchopt">Fork benchopt on Github</a></li>
</ul>
</div>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020-2022, Benchopt contributors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>